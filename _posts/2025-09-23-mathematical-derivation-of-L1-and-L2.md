---
layout: post
math: true
title: "Mathematical Derivation of L1 and L2 Regularization"
categories: deep_learning
tags: [hands-on, regularization, calculus]
---

# L1 和 L2 正则化的数学推导

前面说过，对于 L1 和 L2 正则化过程的区别的直观理解是：
L1 是在参数更新（梯度下降）过程中，每次对权重减去一个固定的小数值，它将会导致一些权重变为零；
L2 是在参数更新时，每次对权重乘以一个小比例因子，使得一些权重会设置为接近但不为零。

下面来看数学推导。

假设有一个简单的线性回归模型：

$$ y = w_1x_1 + w_2x_2 + w_3x_3 + b $$

其中 $w_1, w_2, w_3$ 是模型的权重，$b$ 是偏置项。我们的目标是最小化均方误差（MSE）损失函数：

$$ \text{Loss} = MSE = \frac{1}{n}\sum_{i=1}^n(y_i - \hat{y}_i)^2 $$

$y_i$ 是真实值，$\hat{y}_i$ 是模型预测值，$n$ 是样本数量。

在这个基础上，引入 L1 和 L2 正则化项。

对于 L1 正则化，我们的损失函数变为：

$$ \text{Loss} = MSE + \lambda(|w_1| + |w_2| + |w_3|) $$

对于 L2 正则化，我们的损失函数变为：

$$ \text{Loss} = MSE + \lambda(w_1^2 + w_2^2 + w_3^2) $$

其中 $\lambda$ 是正则化强度的超参数。
为了最小化上面的两个损失函数，我们需要计算梯度并进行梯度下降更新。

## 对 MSE 损失函数求导

对于某个特定的权重 $w_j$，MSE 的梯度为：
$$ \frac{\partial MSE}{\partial w_j} = -\frac{1}{n}\sum_{i=1}^n 2(y_i - \hat{y}_i) \cdot \frac{\partial \hat{y}_i}{\partial w_j} $$

由于 $\hat{y}_i = w_1x_{i1} + w_2x_{i2} + w_3x_{i3} + b$，对 $w_j$ 求导时只有含有 $w_j$ 的项会被保留，因此有：

$$ \frac{\partial \hat{y}_i}{\partial w_j} = x_{ij} $$

其中 $x_{ij}$ 是第 $i$ 个样本的第 $j$ 个特征。

将其代入上式，得到：
$$ \frac{\partial MSE}{\partial w_j} = -\frac{2}{n}\sum_{i=1}^n (y_i - \hat{y}_i) x_{ij} $$

接下来，计算正则化项的梯度。

## L1 正则化

$$ \text{Loss} = MSE + \lambda(|w_1| + |w_2| + |w_3|) $$

由于我们只关心某个特定权重 $|w_j|$ 的梯度，其他权重的导数为零，因此有：

$$ \frac{\partial \text{Loss}}{\partial w_j} = \frac{\partial MSE}{\partial w_j} + \lambda \cdot \text{sign}(w_j) $$

其中 $\text{sign}(w_j)$ 是 $w_j$ 的符号函数，定义为：
$$ \text{sign}(w_j) = \begin{cases}
1 & \text{if } w_j > 0 \\
-1 & \text{if } w_j < 0 \\
0 & \text{if } w_j = 0
\end{cases} $$

对于 L1 正则化, 在每次迭代中，我们这样来来更新权重：

$$ w_j = w_j - \eta \left( \frac{\partial MSE}{\partial w_j} + \lambda \cdot \text{sign}(w_j) \right) $$

其中 $\eta$ 是学习率。

注意观察，$w_j$ 和 $-\eta\lambda \cdot \text{sign}(w_j)$ 是符号相反的两项，而 $\eta\lambda$ 是一个固定值。

也就是说，当 $w_j$ 为正时，$w_j$ 会减少一个固定的小数值；当 $w_j$ 为负时，$w_j$ 会增加一个固定的小数值，L1 正则化的这种特性其实能够使得某些权重在0附近震荡。

而对于在0附近震荡的权重，这也意味着这些权重对于模型的贡献非常小，因此也不难理解，从计算效率的角度看，可以通过设置软阈值的方式，将这些权重直接置为0。

在实际操作中，如果权重 $|\frac{\partial MSE}{\partial w_j}|$ 小于 $\lambda$，我们可以直接将其设置为0：
$$ w_j = 0 \quad \text{if } |\frac{\partial MSE}{\partial w_j}| < \lambda $$

经过梯度更新和软阈值处理的共同作用，形成两种情况：

* 权重精确为 0（如果数据梯度项很小）

* 权重保持非 0（如果数据梯度项很大，超过 $\lambda$）

这就产生了稀疏性：不重要的特征权重为 0，重要的特征权重非 0。这个机制确保了不重要的特征权重不会在 0 附近浪费计算资源，而是直接被剔除。

## L2 正则化

对于 L2 正则化，梯度计算如下：

$$ \text{Loss} = MSE + \lambda(w_1^2 + w_2^2 + w_3^2) $$

由于我们只关心某个特定权重 $w_j$ 的梯度，其他权重的导数为零，因此有：

$$ \frac{\partial \text{Loss}}{\partial w_j} = \frac{\partial MSE}{\partial w_j} + 2\lambda w_j $$

在每次迭代中，我们使用这些梯度来更新权重：

$$ w_j = w_j - \eta \left( \frac{\partial MSE}{\partial w_j} + 2\lambda w_j \right) $$

其中 $\eta$ 是学习率。
重写上式：
$$ w_j = w_j(1 - 2\eta\lambda) - \eta \frac{\partial MSE}{\partial w_j} $$

注意观察式中的 $(1 - 2\eta\lambda)$ 项，由于学习率 $\eta$ 很小，正则化强度 $\lambda$ 也不会太大，因此有：

$$ 0 < 1 - 2\eta\lambda < 1 $$

也就是说，在每次迭代中，$w_j$ 会被乘以一个小于1的比例因子，从而逐渐减小权重的绝对值。
这就解释了为什么 L2 正则化不会将权重变为零，而是将其缩小到接近零的原因。

## 哲学思想

有一句古话说：画虎不成反类犬。在画虎的时候，需要抠出虎的关键特征。在神经网络中，训练的方向要朝着尽量拟合数据的方向走，让画出来的“虎”尽量像“虎”。但是在另一方面，我们希望画出来一只虎，而不是拘泥于画出每一根毛发的细节，是画画，而非照相。

在模型训练过程中，需要有两种力量的相互制衡，一种力推动模型尽量拟合数据，要画得像虎；另一种力推动模型尽量简化，要得其神。

在此目标之下，L1 的设计机制类似于“马太效应”，即“强者愈强，弱者愈弱”。L1 所提供的正则化力，和模型训练过程中的数据力，相互角力。正则化力的大小固定为 $\eta\lambda$，方向总指向 0。
当∣数据梯度项∣>λ：数据力胜出，权重保持非零。
当∣数据梯度项∣≤λ：正则化力胜出，权重被拉向 0。

L1 的哲学是，特征生而不平等，模型训练的过程是要让重要的特征脱颖而出，而不重要的特征被淘汰。
L1 适合特征选择，识别重要的特征和处理高维数据（特征数 >> 样本数）。

如果说L1正则化倾向于"拉开"权重差距，那么L2正则化倾向于"拉平"权重差距。
L2 正则化的哲学是，特征生而平等，不能让少数特征主导模型的预测。
基于上述哲学，L2的惩罚项为$\lambda \sum w_j^2$，梯度为$2\lambda w_j$。可见，特征的权重越大，$2\lambda w_j$ 也越大，受到的惩罚也就越大。

L2 的设计机制类似于：富人应该要多交税，穷人不是不交税，而是可以少交税。

L2 正则化通过引入平方惩罚项，鼓励模型将权重分散到多个特征上，从而降低对单一特征的依赖。这种机制使得模型在面对特征间高度相关的情况时，能够更好地进行泛化。

深度学习是对于人脑的模拟，就像人类向鸟学习飞行，但是我们并没有设计上下挥动的翅膀的机械装置来飞行一样，深度学习对于模型学习能力的构建，体现的是人类的智力之美和数学之美。
