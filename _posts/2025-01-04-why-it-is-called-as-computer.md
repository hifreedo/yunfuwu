---
layout: post
toc: true
title: "My History of Computer"
categories: engineering
tags: [brain, LLM]
---

电脑为什么叫作电脑

很久以前，只需要通过一根细细的电话线，和一只名叫实达之星的拨号上网终端，点击桌面的上网图标，
上网终端会响起一阵熟悉的声音，灯光闪烁一阵，然后，就可以通向外面的世界了。
外面的世界，有一个叫Google Groups的东西，世界各地的人聚集在那里讨论不同的话题。
当Ajax刚刚问世的时候，我需要开发一个基于地图进行标注的网页应用，但是可用的资料太少。
我于是就在Groups上面提问，有网友回答了我的问题，还写了一段示范代码，证明它是能够work的。
后来的通信过程中，他还email了几个mp3文件，是录制的吉它曲，他说他来自意大利，主业是做音乐。

一根细小的电话线，对我对学习和世界的认知，发生了很大的冲击。

后来，深度学习打败了李世石，有一个同事是资深的搜索工程专家，这个事件让他毅然决然地投身到了深度学习领域。
因为做了搜索这么多年，这个事情对他的冲击很大。

我的团队也在随后做了语言对话类的应用，采用的是微博的训练语料和LSTM。当时对话模型的商用场景是智能音箱。
当时相对好一些的是微软小冰。
再后来，随着BERT的出现，感觉看到了NLP的真正曙光。
同时也意味着，之前的算法、技术上的工作，整个业内曾经投入的资源，其实是被抛弃了。

当ChatGPT (2022/11/30)出现以后，几乎每一天的工作我都会用到它，真实地感受到了通过一个对话窗口，我似乎站在了一个团队的基石之上。

俗话说：三个臭皮匠，顶个诸葛亮。大概的意思是，遇事不决，可以和团队成员讨论，大家的意见里面说不定有闪光点。
这个选择，在GPTt出现之前，是对的。在GPT出现之后，工作的模式就被完全改写了。

比如说，在开发当中，遇到了一个网络安全相关的问题，但是团队同事都是工程师出身，没有人有过实际的网络安全方面的经验。
这种情况下，仍然把大家叫到一起来讨论，浪费时间且更危险的是，讨论出的结果和方向很可能是完全错误的。

这种情况之下，默认的解是和GPT讨论，它能够带着专业的行业背景和相关知识，给出你的团队成员给不了的insights。
换句话说，GPT的知识远远超出了个人或者一个团队所能拥有的知识积累。你所要做的，只是抽丝拨茧，问出更好的问题。

每当受益于LLM给出的解决方案的同时，我总是不由自主地想到，这个背后其实是巨大的电力所带来的能量。
第一次工业革命是蒸汽机，第二次工业革命是电力和内燃机，其实时至今日，让人类在“智能”上面提升了一大步的基石，仍然是电力。

以OpenAI GPT3 175B 的参数计，假设训练的显卡是A100，以10,000张的级别，假设训练过程一次成功，用时1个月，消耗的电力约为3000MWH，约为300万度电。Amazon AWS CEO也曾经说过，训练大模型需要的电力供应的级别在1~5GW之间，也即1000~5000 MWH。

在奥特曼打怪兽里面有一集，一个怪兽喜欢跑到高压电线处吸电，所到之处，相应的地区就会发生停电。
LLM这个模型怪兽所需的电量，能够把纽约在用电高峰时间所供应的电力瞬间吸干。
现在，回应你在键盘上敲击的字母的模型，就是用这么多的电力训练出来的，想到这点，我总是有种后背震颤的感觉。这是电力给的文明。

前天的时候，我在笔记本电脑上安装了llama 3.2版本，前后大约只花了5分钟的时间。这个电力怪兽的分身，停留在了电脑的硬盘和内存里面。

从拨号上网到现在，这个时空的穿越才20多年，电脑已今昔相隔。为什么叫电脑，“电脑”这个名称，其实特别好，它就是“电” + “脑”。

这篇短文，原来是打算继续写求导的，开头发了一点感想，结果中间就控制不住写叉了。下一篇再写吧。
